# -*- coding: utf-8 -*-
"""Part3_Semantic Segmentation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Aux-XGS7fqwC7E1BChfARp2b6D3zMSKU
"""

import torch
import torchvision
import torchvision.transforms as transforms
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
import urllib.request
import os
from torchvision.models.segmentation import fcn_resnet50, FCN_ResNet50_Weights
import cv2

# PASCAL VOC classes (21 classes including background)
CLASSES = [
    'background', 'aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus',
    'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike',
    'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor'
]

# Create directories for saving results
for directory in ['input_images', 'feature_maps', 'segmentations']:
    if not os.path.exists(directory):
        os.makedirs(directory)


# Function to download images
def download_image(url, filename):
    try:
        urllib.request.urlretrieve(url, f'input_images/{filename}')
        print(f"Downloaded {filename} successfully")
        return True
    except Exception as e:
        print(f"Failed to download {filename}: {e}")
        return False

# Sample image URLs containing multiple objects from the required classes
# These URLs should lead to images with at least 3 different objects from the PASCAL VOC classes
image_urls = [
    ('https://storage.googleapis.com/kagglesdsdata/datasets/1271215/2118595/VOC2012_test/VOC2012_test/JPEGImages/2008_000014.jpg?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=databundle-worker-v2%40kaggle-161607.iam.gserviceaccount.com%2F20250425%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20250425T022255Z&X-Goog-Expires=345600&X-Goog-SignedHeaders=host&X-Goog-Signature=8c18e736d130dac8cda4e313cc05ebbc8424beb08164d6458f8cc7ab6d8885ead196803ca20dd14523419ac086ec7e99d81e2e7b9f9d42161daf867a6fc74e880fbc890a431c04cc4069ad5c9c23922127c5dd6445c49c3cfd93f00c551b6e6101d1fcbcbdc082423a5c5b5f406f145bc19f1708f04ce705ad561108c4725221a4e8d5d61a3bb294e1950da69a9ce06759c2e6fe766661737eba66d5aa6bbb6bc75d9fc35ece979e533a7bb8d3b67f3e6696409a0b3d767c3725e3a06e0f7b7ad15359e18ec1daec46cae4c624979326415bd725e6636193b90951e6d0644bb3260546ba60c77bd72e5cbf66566184a0fb3581fee4531927b3b7991a50f911c7', 'image1.jpg'),
    ('https://storage.googleapis.com/kagglesdsdata/datasets/1271215/2118595/VOC2012_test/VOC2012_test/JPEGImages/2008_000022.jpg?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=databundle-worker-v2%40kaggle-161607.iam.gserviceaccount.com%2F20250425%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20250425T022255Z&X-Goog-Expires=345600&X-Goog-SignedHeaders=host&X-Goog-Signature=9c84dc07213d2b31cd07fe45ccfa069e6decc8479e269e6e7bfd2af224b3f5e1d03a9303b9e79e1abc8403bf01f1f652ef91866392abd0cd54a0533e8db9703b4f1fe9c493c3ccffd70f4dc9ff7929e6224cb9327134da2416ad8f51bf28f8257476c9faa991944b803a8454f176436383673ab4d92f326d0eec988cf76d80b020c6084aae5e11b8e34e1caf30c56d21c8dc199913e694072aa8e0f23e76a3fd65abc933d7d00bed5781bc088c7fecbe5b18a96771cefe1d6bbf2e97eff71aba9598c84f1e74a198b8b15a3bcd22744d7c31b948426b6b625ec9765a1057256f923545ab74bcd45bfdd9c606151746c88f7b4e2c74a9382e91f42f166232171b', 'image2.jpg'),
    ('https://storage.googleapis.com/kagglesdsdata/datasets/1271215/2118595/VOC2012_test/VOC2012_test/JPEGImages/2008_000046.jpg?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=databundle-worker-v2%40kaggle-161607.iam.gserviceaccount.com%2F20250425%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20250425T022255Z&X-Goog-Expires=345600&X-Goog-SignedHeaders=host&X-Goog-Signature=23cbd8ca965ebf76ae76aee293e08ef2f1bd7cfee46a806aace55336ef1aac624f13c0a6ead323dc4ba30da43260dc3b5d4692b35cae5919ed6f0748b53bd3a86923fecbf893bcd8f5a66e3a705d3d1a4876c1ef8bb4a72200981d0ca26f3311549d780d3d1f5a5b698e6c1e74114514dfd9c4f787a48d4a6801e43225304ec7153eb6c218ff5b67bc5eeb8430f3e731ee2a8a5a09529f721ea507e760d9c9a2a2bb950681b5723630799a28f5e79a52879b43ff0c5b83635d75ad50a4612cc56b699e50d0822a240f46a9fea9551a688fe2eee5822f13c77b71149e854024af4f50ff8ebe1f60d33a04ff6525e55e06c1bdf24d2b4733c0986486b61c068e67', 'image3.jpg'),
    ('https://storage.googleapis.com/kagglesdsdata/datasets/1271215/2118595/VOC2012_test/VOC2012_test/JPEGImages/2008_000102.jpg?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=databundle-worker-v2%40kaggle-161607.iam.gserviceaccount.com%2F20250427%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20250427T045751Z&X-Goog-Expires=345600&X-Goog-SignedHeaders=host&X-Goog-Signature=cb2154873f2ca0bcb7b55e1638d1d2f8a86ebed636cae103e56d29c317d27c13fcbb14f741c8b30d012ab38da5752bfec99b4366081ecff415c03532260a247a6d5ffd78d158b6fd83198db33c14e1170fc1bb70208689061bceee0a5b4b974412debd006eec01e8a70ef43c95200a7243f09c12b76fdf7b063ba8fc2be72d8d72ac9de68b6c68bff21d03ecd7965c72fb505775a22a78f3ba3878837fb961902e0f87ee84b17de3ef2eeb30008f897e0916b3baeb023de0b9e25ac63fb2ec0ac3036aae801da01039e8e31db5117abea763ead05882524a3bb2c4e7279935d56b18e286c8246084dac46e8f093c98d3e91e9445832f88e7d3215f43740dc2d3', 'image4.jpg'),
    ('https://storage.googleapis.com/kagglesdsdata/datasets/1271215/2118595/VOC2012_test/VOC2012_test/JPEGImages/2008_000326.jpg?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=databundle-worker-v2%40kaggle-161607.iam.gserviceaccount.com%2F20250427%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20250427T045858Z&X-Goog-Expires=345600&X-Goog-SignedHeaders=host&X-Goog-Signature=d330db231a25119865e2584c1cb8cd8d697bfe52ee3bd3e388362a3c2a003d8093536d93ad751380926dac1de316744daf9f0824a5e9911c83118cc0689fcaecdd37b007c98da785591074dfb8bea5347d0aee1bc1f44704cd258ab2785f0102ee31acad49793652762cdce28a62dd8a5d13428cdacbeb3a682b988d72a1e4ff7c68f367b13c2de35797cd0d5e2918c5fe05184910034274992f5dbc44fce20dcb1fa17fc57314c06742a8a8244b89e928d28ea192471295c26835dae3d50612bd8c35cde4489e92e020c5230aeeb2c8ad184f3619a98f6fcae7050cc43250cf5a0219643f08af9c924a6670bd37b2ae6cbc2e3a5185adc9a1d40f10341eae4c', 'image5.jpg')
]

# Download the images
for url, filename in image_urls:
    download_image(url, filename)

# Load pretrained FCN model
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"Using device: {device}")

# Load pretrained fcn_resnet50 model
weights = FCN_ResNet50_Weights.DEFAULT
model = fcn_resnet50(weights=weights)
model.eval()
model.to(device)

# Define transformations
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# Color map for segmentation visualization
def get_color_map(num_classes):
    """Generate a color map for segmentation visualization"""
    np.random.seed(42)  # For reproducible colors
    color_map = np.random.randint(0, 255, size=(num_classes, 3), dtype=np.uint8)
    # Make background black
    color_map[0] = [0, 0, 0]
    return color_map

color_map = get_color_map(len(CLASSES))

# Process each image
for idx, (_, filename) in enumerate(image_urls):
    print(f"\nProcessing image {idx+1}: {filename}")

    # Load image
    img_path = f'input_images/{filename}'
    img = Image.open(img_path).convert('RGB')

    # Try different sizes for better segmentation
    sizes = [(300, 300), (500, 500), (800, 800)]
    best_size_idx = 2  # Default to largest size, will be updated based on class detection
    max_classes_detected = 0

    fig, axes = plt.subplots(2, len(sizes) + 1, figsize=(20, 10))

    # Show original image
    axes[0, 0].imshow(img)
    axes[0, 0].set_title('Original Image')
    axes[0, 0].axis('off')
    axes[1, 0].axis('off')

    # Store feature maps and segmentations for each size
    all_feature_grids = []
    all_segmentations = []
    all_detected_classes = []

    for i, size in enumerate(sizes):
        # Resize image
        resized_img = img.resize(size)
        input_tensor = transform(resized_img).unsqueeze(0).to(device)

        # Forward pass
        with torch.no_grad():
            output = model(input_tensor)['out']

        # Get feature maps (before softmax)
        feature_maps = output[0].cpu().numpy()

        # Create segmentation mask
        output_predictions = output.argmax(1).squeeze(0).cpu().numpy()

        # Display feature maps as tiles (21 feature maps for 21 classes)
        num_maps = 21  # FCN outputs 21 feature maps for PASCAL VOC
        tile_size = size[0] // 7, size[1] // 3  # Arrange in 7x3 grid
        feature_grid = np.zeros((tile_size[1] * 3, tile_size[0] * 7, 3), dtype=np.uint8)

        for j in range(num_maps):
            # Normalize feature map for visualization
            feature = feature_maps[j]
            feature = (feature - feature.min()) / (feature.max() - feature.min() + 1e-8)
            feature = (feature * 255).astype(np.uint8)

            # Add to grid
            row = j // 7
            col = j % 7
            start_h, start_w = row * tile_size[1], col * tile_size[0]
            resized_feature = cv2.resize(feature, tile_size)
            colored_feature = cv2.applyColorMap(resized_feature, cv2.COLORMAP_JET)
            feature_grid[start_h:start_h+tile_size[1], start_w:start_w+tile_size[0]] = colored_feature

        # Store feature grid
        all_feature_grids.append(feature_grid)

        # Display feature maps
        axes[0, i+1].imshow(feature_grid)
        axes[0, i+1].set_title(f'Feature Maps (Size: {size[0]}x{size[1]})')
        axes[0, i+1].axis('off')

        # Create colored segmentation
        segmentation = np.zeros((output_predictions.shape[0], output_predictions.shape[1], 3), dtype=np.uint8)
        for label in range(len(CLASSES)):
            segmentation[output_predictions == label] = color_map[label]

        # Store segmentation
        all_segmentations.append(segmentation)

        # Display segmentation
        axes[1, i+1].imshow(segmentation)
        axes[1, i+1].set_title(f'Segmentation (Size: {size[0]}x{size[1]})')
        axes[1, i+1].axis('off')

        # Determine classes detected
        unique_labels = np.unique(output_predictions)
        detected_classes = [CLASSES[i] for i in unique_labels if i < len(CLASSES)]
        detected_classes = [cls for cls in detected_classes if cls != 'background']
        all_detected_classes.append(detected_classes)

        # Update best size if more classes are detected
        if len(detected_classes) > max_classes_detected:
            max_classes_detected = len(detected_classes)
            best_size_idx = i

    plt.tight_layout()
    plt.savefig(f'feature_maps/all_sizes_{idx+1}_{filename[:-4]}.png', dpi=300, bbox_inches='tight')
    plt.show()

    # Save the best feature map and segmentation based on most classes detected
    best_size = sizes[best_size_idx]
    print(f"Best size for {filename}: {best_size[0]}x{best_size[1]}")
    print(f"Detected classes: {all_detected_classes[best_size_idx]}")
    print(f"Number of classes detected: {len(all_detected_classes[best_size_idx])}")

    # Save the best feature map
    cv2.imwrite(f'feature_maps/feature_map_{idx+1}_{filename[:-4]}.png',
                cv2.cvtColor(all_feature_grids[best_size_idx], cv2.COLOR_RGB2BGR))

    # Save the best segmentation
    cv2.imwrite(f'segmentations/segmentation_{idx+1}_{filename[:-4]}.png',
                cv2.cvtColor(all_segmentations[best_size_idx], cv2.COLOR_RGB2BGR))

    # Create a combined image with the input, feature map, and segmentation
    fig, axes = plt.subplots(1, 3, figsize=(15, 5))
    axes[0].imshow(img)
    axes[0].set_title('Input Image')
    axes[0].axis('off')

    axes[1].imshow(all_feature_grids[best_size_idx])
    axes[1].set_title(f'Feature Maps (Size: {best_size[0]}x{best_size[1]})')
    axes[1].axis('off')

    axes[2].imshow(all_segmentations[best_size_idx])
    axes[2].set_title(f'Segmentation (Size: {best_size[0]}x{best_size[1]})')
    axes[2].axis('off')

    plt.tight_layout()
    plt.savefig(f'combined_{idx+1}_{filename[:-4]}.png', dpi=300, bbox_inches='tight')
    plt.show()

# Display color map legend
plt.figure(figsize=(15, 2))
for i, label in enumerate(CLASSES):
    plt.fill_between([i/len(CLASSES), (i+1)/len(CLASSES)], 0, 1, color=color_map[i]/255)
    plt.text((i+0.5)/len(CLASSES), 0.5, label, ha='center', va='center',
             rotation=90 if len(label) > 10 else 0,
             fontsize=8, color='white' if np.mean(color_map[i]) < 128 else 'black')
plt.xlim(0, 1)
plt.ylim(0, 1)
plt.title('Class Color Map')
plt.axis('off')
plt.tight_layout()
plt.savefig('class_color_map.png', dpi=300, bbox_inches='tight')
plt.show()

print("\nAll processing complete. Files have been saved to the following directories:")
print("- Input images: ./input_images/")
print("- Feature maps: ./feature_maps/")
print("- Segmentations: ./segmentations/")
print("- Combined visualizations: ./ (in root directory)")
print("- Class color map: ./class_color_map.png")